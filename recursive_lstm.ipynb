{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.relay.prelude import Prelude\n",
    "from tvm.relay.testing import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_types(input_size, hidden_size, batch_size=1, dtype=\"float32\"):\n",
    "    input_type = relay.TensorType((batch_size, input_size), dtype)\n",
    "    hidden_type = relay.TensorType((batch_size, hidden_size), dtype)\n",
    "    i2h_weight_type = relay.TensorType((4 * hidden_size, input_size), dtype)\n",
    "    h2h_weight_type = relay.TensorType((4 * hidden_size, hidden_size), dtype)\n",
    "    bias_type = relay.TensorType((4 * hidden_size,), dtype)\n",
    "    dense_type = relay.TensorType((batch_size, 4 * hidden_size), dtype)\n",
    "    slice_type = relay.TupleType([hidden_type, hidden_type, hidden_type, hidden_type])\n",
    "    state_type = relay.TupleType([hidden_type, hidden_type])\n",
    "    return input_type, hidden_type, i2h_weight_type, h2h_weight_type, bias_type, dense_type, slice_type, state_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_cell(input_size, hidden_size, batch_size=1, dtype=\"float32\"): \n",
    "    input_type, hidden_type, i2h_weight_type, h2h_weight_type, bias_type, dense_type, \\\n",
    "        slice_type, state_type = get_types(input_size, hidden_size, batch_size, dtype)\n",
    "    inputs = relay.Var(\"inputs\", input_type)\n",
    "    states = relay.Var(\"states\", state_type)\n",
    "    i2h_weight = relay.Var(\"i2h_weight\", i2h_weight_type)\n",
    "    i2h_bias = relay.Var(\"i2h_bias\", bias_type)\n",
    "    h2h_weight = relay.Var(\"h2h_weight\", h2h_weight_type)\n",
    "    h2h_bias = relay.Var(\"h2h_bias\", bias_type)\n",
    "    \n",
    "    builder = relay.ScopeBuilder()\n",
    "    old_h = builder.let((\"old_h\", hidden_type), relay.TupleGetItem(states, 0))\n",
    "    old_c = builder.let((\"old_c\", hidden_type), relay.TupleGetItem(states, 1))\n",
    "    i2h = builder.let((\"i2h\", dense_type),\n",
    "                      layers.dense_add_bias(\n",
    "                          data=inputs,\n",
    "                          units=hidden_size * 4,\n",
    "                          weight=i2h_weight, bias=i2h_bias,\n",
    "                          name=\"i2h\"))\n",
    "    h2h = builder.let((\"h2h\", dense_type),\n",
    "                      layers.dense_add_bias(\n",
    "                          data=old_h,\n",
    "                          units=hidden_size * 4,\n",
    "                          weight=h2h_weight, bias=h2h_bias,\n",
    "                          name=\"h2h\"))\n",
    "    gates = builder.let((\"gates\", dense_type), relay.add(i2h, h2h))\n",
    "    slice_gates = builder.let((\"slice_gates\", slice_type),\n",
    "                              relay.split(gates,\n",
    "                                          indices_or_sections=4,\n",
    "                                          axis=1).astuple())\n",
    "    in_gate = builder.let((\"in_gate\", hidden_type),\n",
    "                          relay.sigmoid(relay.TupleGetItem(slice_gates, 0)))\n",
    "    forget_gate = builder.let((\"forget_gate\", hidden_type),\n",
    "                              relay.sigmoid(relay.TupleGetItem(slice_gates, 1)))\n",
    "    in_transform = builder.let((\"in_transform\", hidden_type),\n",
    "                               relay.tanh(relay.TupleGetItem(slice_gates, 2)))\n",
    "    out_gate = builder.let((\"out_gate\", hidden_type),\n",
    "                           relay.sigmoid(relay.TupleGetItem(slice_gates, 3)))\n",
    "    next_c = builder.let((\"next_c\", hidden_type),\n",
    "                         relay.add(relay.multiply(forget_gate, old_c),\n",
    "                                   relay.multiply(in_gate, in_transform)))\n",
    "    next_h = builder.let((\"next_h\", input_type),\n",
    "                         relay.multiply(out_gate, relay.tanh(next_c)))\n",
    "    ret = builder.let((\"ret\", state_type), relay.Tuple([next_h, next_c]))\n",
    "    builder.ret(ret)\n",
    "\n",
    "    return relay.Function([inputs, states, i2h_weight, i2h_bias, h2h_weight, h2h_bias],\n",
    "                          builder.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = relay.Module()\n",
    "p = Prelude(mod)\n",
    "l = p.l\n",
    "nil = p.nil\n",
    "cons = p.cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_lstm(seq_len, input_size, hidden_size, batch_size=1, dtype=\"float32\"):\n",
    "    input_type, hidden_type, i2h_weight_type, h2h_weight_type, bias_type, _, \\\n",
    "        _, state_type = get_types(input_size, hidden_size, batch_size, dtype)\n",
    "    \n",
    "    input_seq = nil()\n",
    "    for i in range(seq_len):\n",
    "        inputs = relay.Var(\"data\", input_type)\n",
    "        input_seq = cons(inputs, input_seq)\n",
    "    \n",
    "    i2h_weight = relay.Var(\"i2h_weight\", i2h_weight_type)\n",
    "    i2h_bias = relay.Var(\"i2h_bias\", bias_type)\n",
    "    h2h_weight = relay.Var(\"h2h_weight\", h2h_weight_type)\n",
    "    h2h_bias = relay.Var(\"h2h_bias\", bias_type)\n",
    "    \n",
    "    current_seq = relay.Var(\"current_seq\", l(input_type))\n",
    "    current_inputs = relay.Var(\"current_inputs\", input_type)\n",
    "    tail_seq = relay.Var(\"tail_seq\", l(input_type))\n",
    "    \n",
    "    rec_fn = relay.Var(\"rec_fn\")\n",
    "    cell_fn = lstm_cell(input_size, hidden_size, batch_size, dtype)\n",
    "    \n",
    "    builder = relay.ScopeBuilder()\n",
    "    zeros = builder.let((\"zeros\", hidden_type), relay.zeros((batch_size, hidden_size), dtype))\n",
    "    init_states = builder.let((\"init_states\", state_type), relay.Tuple([zeros, zeros]))\n",
    "    match = builder.let((\"match\", state_type), \n",
    "        relay.Match(\n",
    "            current_seq,\n",
    "            [relay.Clause(relay.PatternConstructor(nil), \n",
    "                          init_states),\n",
    "             relay.Clause(relay.PatternConstructor(cons,\n",
    "                                                   [relay.PatternVar(current_inputs), \n",
    "                                                    relay.PatternVar(tail_seq)]),\n",
    "                          relay.Call(cell_fn, [current_inputs, rec_fn(tail_seq),\n",
    "                                               i2h_weight, i2h_bias, h2h_weight, h2h_bias]))\n",
    "            ]))\n",
    "    builder.ret(match)\n",
    "    func = relay.Function([current_seq], builder.get())\n",
    "    ret = relay.Let(rec_fn, func, rec_fn(input_seq))\n",
    "    out = relay.TupleGetItem(ret, 0)\n",
    "    args = relay.analysis.free_vars(out)\n",
    "    return relay.Function(args, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0.0.4\n",
      "fn (%i2h_weight: Tensor[(8, 2), float32], %i2h_bias: Tensor[(8), float32], %h2h_weight: Tensor[(8, 2), float32], %h2h_bias: Tensor[(8), float32], %data: Tensor[(1, 2), float32], %data1: Tensor[(1, 2), float32]) -> Tensor[(1, 2), float32] {\n",
      "  %14 = (\n",
      "    let %rec_fn-malformed-ir = fn (%current_seq: List[Tensor[(1, 2), float32]]) -> (Tensor[(1, 2), float32], Tensor[(1, 2), float32]) {\n",
      "      let %zeros: Tensor[(1, 2), float32] = zeros(shape=[1, 2], dtype=\"float32\") /* ty=Tensor[(1, 2), float32] */;\n",
      "      let %init_states: (Tensor[(1, 2), float32], Tensor[(1, 2), float32]) = (%zeros, %zeros);\n",
      "      let %match: (Tensor[(1, 2), float32], Tensor[(1, 2), float32]) = match (%current_seq) {\n",
      "        Nil => %init_states,\n",
      "        Cons(%current_inputs: Tensor[(1, 2), float32], %tail_seq: List[Tensor[(1, 2), float32]]) => free_var %rec_fn: fn (List[Tensor[(1, 2), float32]]) -> (Tensor[(1, 2), float32], Tensor[(1, 2), float32])\n",
      "        %0 = %rec_fn(%tail_seq) /* ty=(Tensor[(1, 2), float32], Tensor[(1, 2), float32]) */;\n",
      "        %10 = fn (%inputs: Tensor[(1, 2), float32], %states: (Tensor[(1, 2), float32], Tensor[(1, 2), float32]), %i2h_weight1: Tensor[(8, 2), float32], %i2h_bias1: Tensor[(8), float32], %h2h_weight1: Tensor[(8, 2), float32], %h2h_bias1: Tensor[(8), float32]) -> (Tensor[(1, 2), float32], Tensor[(1, 2), float32]) {\n",
      "          let %old_h: Tensor[(1, 2), float32] = %states.0;\n",
      "          let %old_c: Tensor[(1, 2), float32] = %states.1;\n",
      "          %1 = nn.dense(%inputs, %i2h_weight1, units=8) /* ty=Tensor[(1, 8), float32] */;\n",
      "          let %i2h: Tensor[(1, 8), float32] = nn.bias_add(%1, %i2h_bias1, axis=-1) /* ty=Tensor[(1, 8), float32] */;\n",
      "          %2 = nn.dense(%old_h, %h2h_weight1, units=8) /* ty=Tensor[(1, 8), float32] */;\n",
      "          let %h2h: Tensor[(1, 8), float32] = nn.bias_add(%2, %h2h_bias1, axis=-1) /* ty=Tensor[(1, 8), float32] */;\n",
      "          let %gates: Tensor[(1, 8), float32] = add(%i2h, %h2h) /* ty=Tensor[(1, 8), float32] */;\n",
      "          let %slice_gates: (Tensor[(1, 2), float32], Tensor[(1, 2), float32], Tensor[(1, 2), float32], Tensor[(1, 2), float32]) = split(%gates, indices_or_sections=4, axis=1) /* ty=(Tensor[(1, 2), float32], Tensor[(1, 2), float32], Tensor[(1, 2), float32], Tensor[(1, 2), float32]) */;\n",
      "          %3 = %slice_gates.0;\n",
      "          let %in_gate: Tensor[(1, 2), float32] = sigmoid(%3) /* ty=Tensor[(1, 2), float32] */;\n",
      "          %4 = %slice_gates.1;\n",
      "          let %forget_gate: Tensor[(1, 2), float32] = sigmoid(%4) /* ty=Tensor[(1, 2), float32] */;\n",
      "          %5 = %slice_gates.2;\n",
      "          let %in_transform: Tensor[(1, 2), float32] = tanh(%5) /* ty=Tensor[(1, 2), float32] */;\n",
      "          %6 = %slice_gates.3;\n",
      "          let %out_gate: Tensor[(1, 2), float32] = sigmoid(%6) /* ty=Tensor[(1, 2), float32] */;\n",
      "          %7 = multiply(%forget_gate, %old_c) /* ty=Tensor[(1, 2), float32] */;\n",
      "          %8 = multiply(%in_gate, %in_transform) /* ty=Tensor[(1, 2), float32] */;\n",
      "          let %next_c: Tensor[(1, 2), float32] = add(%7, %8) /* ty=Tensor[(1, 2), float32] */;\n",
      "          %9 = tanh(%next_c) /* ty=Tensor[(1, 2), float32] */;\n",
      "          let %next_h: Tensor[(1, 2), float32] = multiply(%out_gate, %9) /* ty=Tensor[(1, 2), float32] */;\n",
      "          let %ret: (Tensor[(1, 2), float32], Tensor[(1, 2), float32]) = (%next_h, %next_c);\n",
      "          %ret\n",
      "        };\n",
      "        %10(%current_inputs, %0, %i2h_weight, %i2h_bias, %h2h_weight, %h2h_bias) /* ty=(Tensor[(1, 2), float32], Tensor[(1, 2), float32]) */,\n",
      "      };\n",
      "      %match\n",
      "    };\n",
      "    %11 = Nil /* ty=List[Tensor[(1, 2), float32]] */;\n",
      "    %12 = Cons(%data1, %11) /* ty=List[Tensor[(1, 2), float32]] */;\n",
      "    %13 = Cons(%data, %12) /* ty=List[Tensor[(1, 2), float32]] */;\n",
      "    %rec_fn(%13) /* ty=(Tensor[(1, 2), float32], Tensor[(1, 2), float32]) */\n",
      "  );\n",
      "  %14.0\n",
      "}\n",
      "[[-0.09028637 -0.35553432]]\n"
     ]
    }
   ],
   "source": [
    "mod[\"main\"] = recursive_lstm(2, 2, 2)\n",
    "print(mod[\"main\"])\n",
    "mod = relay.transform.InferType()(mod)\n",
    "# mod = relay.transform.LambdaLift()(mod)\n",
    "# print(mod[\"main\"])\n",
    "# print(mod[\"main\"].params)\n",
    "\n",
    "inputs = []\n",
    "for v in mod[\"main\"].params:\n",
    "    t = v.checked_type\n",
    "    rand_value = np.random.normal(size=t.concrete_shape).astype(t.dtype)\n",
    "#     inputs.append(rand_value)\n",
    "    inputs.append(tvm.nd.array(rand_value, ctx=tvm.cpu(0)))\n",
    "# print(inputs)\n",
    "\n",
    "# intrp = relay.create_executor(\"debug\", mod=mod, ctx=tvm.cpu(), target=\"llvm\")\n",
    "# res = intrp.evaluate()(*inputs)\n",
    "# print(res)\n",
    "\n",
    "ctx = tvm.cpu()\n",
    "target = \"llvm\"\n",
    "vm = relay.create_executor('debug', ctx=tvm.cpu(), target=target, mod=mod)\n",
    "result = vm.evaluate()(*inputs)\n",
    "print(result.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_anaconda3)",
   "language": "python",
   "name": "conda_anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
