{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relay has not yet supported tail recursive optimization\n",
    "some implemented optimizations:\n",
    "- A-Normal Form\n",
    "- Lambda Lift\n",
    "- Inline Primitives\n",
    "- Inliner\n",
    "- Constant Pool Layout\n",
    "- ADT Tag Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relay has operators to get the shape of a tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_shape_of():\n",
    "    a = relay.var('a', shape=(2, 2), dtype='float32')\n",
    "    b = relay.var('b', shape=(2, 2), dtype='float32')\n",
    "    c = relay.add(a, b)\n",
    "    s = relay.shape_of(c)\n",
    "    s0 = relay.take(s, relay.const(0, 'int32'))\n",
    "    s1 = s0 + relay.const(1, 'int32')\n",
    "    func = relay.Function([a, b], s1)\n",
    "    mod = relay.Module()\n",
    "    mod[\"main\"] = func\n",
    "    print(mod)\n",
    "    \n",
    "    for kind in [\"debug\", \"vm\"]:\n",
    "        print('result in', kind)\n",
    "        ex = relay.create_executor(kind, mod=mod, ctx=tvm.cpu(), target=\"llvm\")\n",
    "        result = ex.evaluate()(np.zeros((2, 2), dtype='float32'), np.zeros((2, 2), dtype='float32'))\n",
    "        print(result.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0.0.4\n",
      "def @main(%a: Tensor[(2, 2), float32], %b: Tensor[(2, 2), float32]) -> int32 {\n",
      "  %0 = add(%a, %b) /* ty=Tensor[(2, 2), float32] */;\n",
      "  %1 = shape_of(%0, dtype=\"int32\") /* ty=Tensor[(2), int32] */;\n",
      "  %2 = take(%1, 0 /* ty=int32 */) /* ty=int32 */;\n",
      "  add(%2, 1 /* ty=int32 */) /* ty=int32 */\n",
      "}\n",
      "\n",
      "result in debug\n",
      "3\n",
      "result in vm\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "show_shape_of()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Does relay support operators like `unique`, `boolean_mask`?\n",
    "Currently there is no Relay API like `relay.unique` or `relay.boolean_mask` but they are in progress. \n",
    "\n",
    "Some discussions about supporting dynamic shape:\n",
    "- [Design problems for Relay to support NLP models](https://discuss.tvm.ai/t/design-problems-for-relay-to-support-nlp-models/1631/7)\n",
    "- [Handling operators like `np.unique`, `boolean indexing` in relay](https://discuss.tvm.ai/t/handling-operators-like-np-unique-boolean-indexing-in-relay/1229)\n",
    "- [[RFC][Relay] Dynamic Dimensions #3042](https://github.com/apache/incubator-tvm/issues/3042)\n",
    "\n",
    "TVM v0.6 has already implemented type checking for Any. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def any_dims(ndim):\n",
    "    shape = []\n",
    "    for _ in range(ndim):\n",
    "        shape.append(relay.Any())\n",
    "    return tuple(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_any_broadcast(x_shape, y_shape, x_np_shape, y_np_shape, op, np_op):\n",
    "    dtype = 'float32'\n",
    "    x = relay.var('x', shape=x_shape, dtype=dtype)\n",
    "    y = relay.var('y', shape=y_shape, dtype=dtype)\n",
    "    mod = relay.module.Module()\n",
    "    mod[\"main\"] = relay.Function([x, y], op(x, y))\n",
    "    print(mod)\n",
    "    \n",
    "    x_np = np.random.uniform(size=x_np_shape).astype(dtype)\n",
    "    y_np = np.random.uniform(size=y_np_shape).astype(dtype)\n",
    "    res_np = np_op(x_np, y_np)\n",
    "    for kind in [\"debug\", \"vm\"]:\n",
    "        print('result in', kind)\n",
    "        ex = relay.create_executor(kind, mod=mod, ctx=tvm.cpu(), target=\"llvm\")\n",
    "        result = ex.evaluate()(x_np, y_np)\n",
    "        print(result.asnumpy())\n",
    "        tvm.testing.assert_allclose(result.asnumpy(), res_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0.0.4\n",
      "def @main(%x: Tensor[(?, 2), float32], %y: Tensor[(1, 2), float32]) -> Tensor[(?, 2), float32] {\n",
      "  add(%x, %y) /* ty=Tensor[(?, 2), float32] */\n",
      "}\n",
      "\n",
      "result in debug\n",
      "[[1.7161348 1.7575006]]\n",
      "result in vm\n",
      "[[1.7161348 1.7575006]]\n"
     ]
    }
   ],
   "source": [
    "show_any_broadcast((relay.Any(), 2), (1, 2), (1, 2), (1, 2), relay.add, np.add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_arange():\n",
    "    m, n, k = relay.ShapeVar('m'), relay.ShapeVar('n'), relay.ShapeVar('k')\n",
    "    x = relay.var('x', shape=(m.var, n.var, k.var), dtype='float32')\n",
    "    y0 = relay.shape_of(x)\n",
    "    y1 = relay.take(y0, relay.const(0, 'int32'))\n",
    "    y2 = relay.op.arange(y1, dtype='int32')\n",
    "    y3 = y2 + relay.const(1, dtype='int32')\n",
    "    mod = relay.module.Module()\n",
    "    mod['main'] = relay.Function([x], y3, type_params=[m, n, k])\n",
    "    print(mod)\n",
    "\n",
    "    data = np.random.rand(10, 5, 3).astype('float32')\n",
    "    for kind in ['debug', 'vm']:\n",
    "        print('result in', kind)\n",
    "        ex = relay.create_executor(kind, mod=mod, ctx=tvm.cpu(), target='llvm')\n",
    "        result = ex.evaluate()(data)\n",
    "        print(result.asnumpy())\n",
    "        tvm.testing.assert_allclose(result.asnumpy(), np.array(range(10)).astype(\"int32\")+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0.0.4\n",
      "def @main[m, n, k](%x: Tensor[(meta[Variable][0], meta[Variable][1], meta[Variable][2]), float32]) -> Tensor[(?), int32] {\n",
      "  %0 = shape_of(%x, dtype=\"int32\") /* ty=Tensor[(3), int32] */;\n",
      "  %1 = take(%0, 0 /* ty=int32 */) /* ty=int32 */;\n",
      "  %2 = arange(0 /* ty=int32 */, %1, 1 /* ty=int32 */, start=meta[relay.Constant][0], stop=meta[relay.Call][0], step=meta[relay.Constant][1], dtype=\"int32\") /* ty=Tensor[(?), int32] */;\n",
      "  add(%2, 1 /* ty=int32 */) /* ty=Tensor[(?), int32] */\n",
      "}\n",
      "\n",
      "// meta data omitted. you can use show_meta_data=True to include meta data\n",
      "result in debug\n",
      "[ 1  2  3  4  5  6  7  8  9 10]\n",
      "result in vm\n",
      "[ 1  2  3  4  5  6  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "show_arange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_anaconda3)",
   "language": "python",
   "name": "conda_anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
