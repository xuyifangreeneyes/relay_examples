{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.relay.prelude import Prelude\n",
    "from tvm.relay.testing import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_types(input_size, hidden_size, batch_size=1, dtype=\"float32\"):\n",
    "    input_type = relay.TensorType((batch_size, input_size), dtype)\n",
    "    hidden_type = relay.TensorType((batch_size, hidden_size), dtype)\n",
    "    i2h_weight_type = relay.TensorType((4 * hidden_size, input_size), dtype)\n",
    "    h2h_weight_type = relay.TensorType((4 * hidden_size, hidden_size), dtype)\n",
    "    bias_type = relay.TensorType((4 * hidden_size,), dtype)\n",
    "    dense_type = relay.TensorType((batch_size, 4 * hidden_size), dtype)\n",
    "    slice_type = relay.TupleType([hidden_type, hidden_type, hidden_type, hidden_type])\n",
    "    state_type = relay.TupleType([hidden_type, hidden_type])\n",
    "    return input_type, hidden_type, i2h_weight_type, h2h_weight_type, bias_type, dense_type, slice_type, state_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_cell(input_size, hidden_size, batch_size=1, dtype=\"float32\"): \n",
    "    input_type, hidden_type, i2h_weight_type, h2h_weight_type, bias_type, dense_type, \\\n",
    "        slice_type, state_type = get_types(input_size, hidden_size, batch_size, dtype)\n",
    "    inputs = relay.Var(\"inputs\", input_type)\n",
    "    states = relay.Var(\"states\", state_type)\n",
    "    i2h_weight = relay.Var(\"i2h_weight\", i2h_weight_type)\n",
    "    i2h_bias = relay.Var(\"i2h_bias\", bias_type)\n",
    "    h2h_weight = relay.Var(\"h2h_weight\", h2h_weight_type)\n",
    "    h2h_bias = relay.Var(\"h2h_bias\", bias_type)\n",
    "    \n",
    "    builder = relay.ScopeBuilder()\n",
    "    old_h = builder.let((\"old_h\", hidden_type), relay.TupleGetItem(states, 0))\n",
    "    old_c = builder.let((\"old_c\", hidden_type), relay.TupleGetItem(states, 1))\n",
    "    i2h = builder.let((\"i2h\", dense_type),\n",
    "                      layers.dense_add_bias(\n",
    "                          data=inputs,\n",
    "                          units=hidden_size * 4,\n",
    "                          weight=i2h_weight, bias=i2h_bias,\n",
    "                          name=\"i2h\"))\n",
    "    h2h = builder.let((\"h2h\", dense_type),\n",
    "                      layers.dense_add_bias(\n",
    "                          data=old_h,\n",
    "                          units=hidden_size * 4,\n",
    "                          weight=h2h_weight, bias=h2h_bias,\n",
    "                          name=\"h2h\"))\n",
    "    gates = builder.let((\"gates\", dense_type), relay.add(i2h, h2h))\n",
    "    slice_gates = builder.let((\"slice_gates\", slice_type),\n",
    "                              relay.split(gates,\n",
    "                                          indices_or_sections=4,\n",
    "                                          axis=1).astuple())\n",
    "    in_gate = builder.let((\"in_gate\", hidden_type),\n",
    "                          relay.sigmoid(relay.TupleGetItem(slice_gates, 0)))\n",
    "    forget_gate = builder.let((\"forget_gate\", hidden_type),\n",
    "                              relay.sigmoid(relay.TupleGetItem(slice_gates, 1)))\n",
    "    in_transform = builder.let((\"in_transform\", hidden_type),\n",
    "                               relay.tanh(relay.TupleGetItem(slice_gates, 2)))\n",
    "    out_gate = builder.let((\"out_gate\", hidden_type),\n",
    "                           relay.sigmoid(relay.TupleGetItem(slice_gates, 3)))\n",
    "    next_c = builder.let((\"next_c\", hidden_type),\n",
    "                         relay.add(relay.multiply(forget_gate, old_c),\n",
    "                                   relay.multiply(in_gate, in_transform)))\n",
    "    next_h = builder.let((\"next_h\", input_type),\n",
    "                         relay.multiply(out_gate, relay.tanh(next_c)))\n",
    "    ret = builder.let((\"ret\", state_type), relay.Tuple([next_h, next_c]))\n",
    "    builder.ret(ret)\n",
    "\n",
    "    return relay.Function([inputs, states, i2h_weight, i2h_bias, h2h_weight, h2h_bias],\n",
    "                          builder.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unroll_lstm(seq_len, input_size, hidden_size, batch_size=1, dtype=\"float32\"):\n",
    "    input_type, hidden_type, i2h_weight_type, h2h_weight_type, bias_type, _, \\\n",
    "        _, state_type = get_types(input_size, hidden_size, batch_size, dtype)\n",
    "    \n",
    "    i2h_weight = relay.Var(\"i2h_weight\", i2h_weight_type)\n",
    "    i2h_bias = relay.Var(\"i2h_bias\", bias_type)\n",
    "    h2h_weight = relay.Var(\"h2h_weight\", h2h_weight_type)\n",
    "    h2h_bias = relay.Var(\"h2h_bias\", bias_type)\n",
    "    \n",
    "    cell_fn = lstm_cell(input_size, hidden_size, batch_size, dtype)\n",
    "    \n",
    "    builder = relay.ScopeBuilder()\n",
    "    zeros = builder.let((\"zeros\", hidden_type), relay.zeros((batch_size, hidden_size), dtype))\n",
    "    states = builder.let((\"init_states\", state_type), relay.Tuple([zeros, zeros]))\n",
    "    \n",
    "    for i in range(seq_len):\n",
    "        inputs = relay.Var(\"data_\" + str(i), input_type)\n",
    "        new_states = builder.let((\"call\", state_type),\n",
    "                                 relay.Call(cell_fn, [inputs, states, i2h_weight, \n",
    "                                                      i2h_bias, h2h_weight, h2h_bias]))\n",
    "        states = new_states\n",
    "    \n",
    "    out = builder.let((\"out\", hidden_type), relay.TupleGetItem(states, 0))\n",
    "    builder.ret(out)\n",
    "    body = builder.get()\n",
    "    args = relay.analysis.free_vars(body)\n",
    "    return relay.Function(args, body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0.0.4\n",
      "fn (%data_0: Tensor[(1, 2), float32], %i2h_weight: Tensor[(8, 2), float32], %i2h_bias: Tensor[(8), float32], %h2h_weight: Tensor[(8, 2), float32], %h2h_bias: Tensor[(8), float32], %data_1: Tensor[(1, 2), float32]) -> Tensor[(1, 2), float32] {\n",
      "  let %zeros: Tensor[(1, 2), float32] = zeros(shape=[1, 2], dtype=\"float32\") /* ty=Tensor[(1, 2), float32] */;\n",
      "  let %init_states: (Tensor[(1, 2), float32], Tensor[(1, 2), float32]) = (%zeros, %zeros);\n",
      "  %9 = fn (%inputs: Tensor[(1, 2), float32], %states: (Tensor[(1, 2), float32], Tensor[(1, 2), float32]), %i2h_weight1: Tensor[(8, 2), float32], %i2h_bias1: Tensor[(8), float32], %h2h_weight1: Tensor[(8, 2), float32], %h2h_bias1: Tensor[(8), float32]) -> (Tensor[(1, 2), float32], Tensor[(1, 2), float32]) {\n",
      "    let %old_h: Tensor[(1, 2), float32] = %states.0;\n",
      "    let %old_c: Tensor[(1, 2), float32] = %states.1;\n",
      "    %0 = nn.dense(%inputs, %i2h_weight1, units=8) /* ty=Tensor[(1, 8), float32] */;\n",
      "    let %i2h: Tensor[(1, 8), float32] = nn.bias_add(%0, %i2h_bias1, axis=-1) /* ty=Tensor[(1, 8), float32] */;\n",
      "    %1 = nn.dense(%old_h, %h2h_weight1, units=8) /* ty=Tensor[(1, 8), float32] */;\n",
      "    let %h2h: Tensor[(1, 8), float32] = nn.bias_add(%1, %h2h_bias1, axis=-1) /* ty=Tensor[(1, 8), float32] */;\n",
      "    let %gates: Tensor[(1, 8), float32] = add(%i2h, %h2h) /* ty=Tensor[(1, 8), float32] */;\n",
      "    let %slice_gates: (Tensor[(1, 2), float32], Tensor[(1, 2), float32], Tensor[(1, 2), float32], Tensor[(1, 2), float32]) = split(%gates, indices_or_sections=4, axis=1) /* ty=(Tensor[(1, 2), float32], Tensor[(1, 2), float32], Tensor[(1, 2), float32], Tensor[(1, 2), float32]) */;\n",
      "    %2 = %slice_gates.0;\n",
      "    let %in_gate: Tensor[(1, 2), float32] = sigmoid(%2) /* ty=Tensor[(1, 2), float32] */;\n",
      "    %3 = %slice_gates.1;\n",
      "    let %forget_gate: Tensor[(1, 2), float32] = sigmoid(%3) /* ty=Tensor[(1, 2), float32] */;\n",
      "    %4 = %slice_gates.2;\n",
      "    let %in_transform: Tensor[(1, 2), float32] = tanh(%4) /* ty=Tensor[(1, 2), float32] */;\n",
      "    %5 = %slice_gates.3;\n",
      "    let %out_gate: Tensor[(1, 2), float32] = sigmoid(%5) /* ty=Tensor[(1, 2), float32] */;\n",
      "    %6 = multiply(%forget_gate, %old_c) /* ty=Tensor[(1, 2), float32] */;\n",
      "    %7 = multiply(%in_gate, %in_transform) /* ty=Tensor[(1, 2), float32] */;\n",
      "    let %next_c: Tensor[(1, 2), float32] = add(%6, %7) /* ty=Tensor[(1, 2), float32] */;\n",
      "    %8 = tanh(%next_c) /* ty=Tensor[(1, 2), float32] */;\n",
      "    let %next_h: Tensor[(1, 2), float32] = multiply(%out_gate, %8) /* ty=Tensor[(1, 2), float32] */;\n",
      "    let %ret: (Tensor[(1, 2), float32], Tensor[(1, 2), float32]) = (%next_h, %next_c);\n",
      "    %ret\n",
      "  };\n",
      "  let %call: (Tensor[(1, 2), float32], Tensor[(1, 2), float32]) = %9(%data_0, %init_states, %i2h_weight, %i2h_bias, %h2h_weight, %h2h_bias) /* ty=(Tensor[(1, 2), float32], Tensor[(1, 2), float32]) */;\n",
      "  let %call1: (Tensor[(1, 2), float32], Tensor[(1, 2), float32]) = %9(%data_1, %call, %i2h_weight, %i2h_bias, %h2h_weight, %h2h_bias) /* ty=(Tensor[(1, 2), float32], Tensor[(1, 2), float32]) */;\n",
      "  let %out: Tensor[(1, 2), float32] = %call1.0;\n",
      "  %out\n",
      "}\n",
      "[Var(data_0, ty=TensorType([1, 2], float32)), Var(i2h_weight, ty=TensorType([8, 2], float32)), Var(i2h_bias, ty=TensorType([8], float32)), Var(h2h_weight, ty=TensorType([8, 2], float32)), Var(h2h_bias, ty=TensorType([8], float32)), Var(data_1, ty=TensorType([1, 2], float32))]\n",
      "{'i2h_weight': <tvm.NDArray shape=(8, 2), cpu(0)>\n",
      "array([[ 0.07562155,  0.33336994],\n",
      "       [ 0.15920034,  0.06953273],\n",
      "       [-0.11827347,  0.22601819],\n",
      "       [-0.09668948,  0.6069321 ],\n",
      "       [ 0.71830326, -0.18057162],\n",
      "       [ 0.45193848,  0.04476382],\n",
      "       [ 0.10541418,  0.6593315 ],\n",
      "       [-0.6645481 , -0.63961655]], dtype=float32), 'i2h_bias': <tvm.NDArray shape=(8,), cpu(0)>\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), 'h2h_weight': <tvm.NDArray shape=(8, 2), cpu(0)>\n",
      "array([[-0.74327445,  0.51529247],\n",
      "       [ 0.43091857,  0.5732204 ],\n",
      "       [ 0.74147236,  0.46345446],\n",
      "       [-0.05967592,  0.43459395],\n",
      "       [-0.5913667 ,  0.21676472],\n",
      "       [-0.55251473,  0.6888781 ],\n",
      "       [ 0.03384728, -0.13220516],\n",
      "       [-0.36474887,  0.42484102]], dtype=float32), 'h2h_bias': <tvm.NDArray shape=(8,), cpu(0)>\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "mod = relay.Module()\n",
    "mod[\"main\"] = unroll_lstm(2, 2, 2)\n",
    "mod = relay.transform.InferType()(mod)\n",
    "print(mod[\"main\"])\n",
    "print(mod[\"main\"].params)\n",
    "   \n",
    "shape_dict = {\n",
    "    v.name_hint : v.checked_type for v in mod[\"main\"].params}\n",
    "np.random.seed(0)\n",
    "initializer = relay.testing.init.Xavier()\n",
    "params = {}\n",
    "for k, v in shape_dict.items():\n",
    "    if k.startswith(\"data\"):\n",
    "        continue\n",
    "    init_value = np.zeros(v.concrete_shape).astype(v.dtype)\n",
    "    initializer(k, init_value)\n",
    "    params[k] = tvm.nd.array(init_value, ctx=tvm.cpu(0))\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TVMError",
     "evalue": "Traceback (most recent call last):\n  [bt] (8) /home/ubuntu/tvm/build/libtvm.so(tvm::relay::backend::GraphRuntimeCodegen::VisitExpr(tvm::relay::Expr const&)+0x47f) [0x7f5bb4d3464f]\n  [bt] (7) /home/ubuntu/tvm/build/libtvm.so(tvm::relay::backend::GraphRuntimeCodegen::VisitExpr_(tvm::relay::LetNode const*)+0x18b) [0x7f5bb4d33c4b]\n  [bt] (6) /home/ubuntu/tvm/build/libtvm.so(tvm::relay::backend::GraphRuntimeCodegen::VisitExpr(tvm::relay::Expr const&)+0x47f) [0x7f5bb4d3464f]\n  [bt] (5) /home/ubuntu/tvm/build/libtvm.so(tvm::relay::backend::GraphRuntimeCodegen::VisitExpr_(tvm::relay::LetNode const*)+0x18b) [0x7f5bb4d33c4b]\n  [bt] (4) /home/ubuntu/tvm/build/libtvm.so(tvm::relay::backend::GraphRuntimeCodegen::VisitExpr(tvm::relay::Expr const&)+0x47f) [0x7f5bb4d3464f]\n  [bt] (3) /home/ubuntu/tvm/build/libtvm.so(tvm::relay::backend::GraphRuntimeCodegen::VisitExpr_(tvm::relay::LetNode const*)+0x147) [0x7f5bb4d33c07]\n  [bt] (2) /home/ubuntu/tvm/build/libtvm.so(tvm::relay::backend::GraphRuntimeCodegen::VisitExpr(tvm::relay::Expr const&)+0x42d) [0x7f5bb4d345fd]\n  [bt] (1) /home/ubuntu/tvm/build/libtvm.so(tvm::relay::backend::GraphRuntimeCodegen::VisitExpr_(tvm::relay::CallNode const*)+0xd92) [0x7f5bb4d3a062]\n  [bt] (0) /home/ubuntu/tvm/build/libtvm.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x32) [0x7f5bb46c2352]\n  File \"/home/ubuntu/tvm/src/relay/backend/graph_runtime_codegen.cc\", line 397\nTVMError: TVM only support calls to primitive functions (i.e functions composed of fusable operator invocations)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-498d667ce842>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mrelay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     graph, lib, params = relay.build_module.build(\n\u001b[0;32m----> 5\u001b[0;31m         mod, target, params=params)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tvm/python/tvm/relay/build_module.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(mod, target, target_host, params)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtophub_context\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mbld_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBuildModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mgraph_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbld_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tvm/python/tvm/relay/build_module.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, func, target, target_host, params)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m# Build the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_host\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;31m# Get artifacts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mgraph_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tvm/python/tvm/_ffi/_ctypes/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 ctypes.byref(ret_val), ctypes.byref(ret_tcode)) != 0:\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mget_last_ffi_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTVMError\u001b[0m: Traceback (most recent call last):\n  [bt] (8) /home/ubuntu/tvm/build/libtvm.so(tvm::relay::backend::GraphRuntimeCodegen::VisitExpr(tvm::relay::Expr const&)+0x47f) [0x7f5bb4d3464f]\n  [bt] (7) /home/ubuntu/tvm/build/libtvm.so(tvm::relay::backend::GraphRuntimeCodegen::VisitExpr_(tvm::relay::LetNode const*)+0x18b) [0x7f5bb4d33c4b]\n  [bt] (6) /home/ubuntu/tvm/build/libtvm.so(tvm::relay::backend::GraphRuntimeCodegen::VisitExpr(tvm::relay::Expr const&)+0x47f) [0x7f5bb4d3464f]\n  [bt] (5) /home/ubuntu/tvm/build/libtvm.so(tvm::relay::backend::GraphRuntimeCodegen::VisitExpr_(tvm::relay::LetNode const*)+0x18b) [0x7f5bb4d33c4b]\n  [bt] (4) /home/ubuntu/tvm/build/libtvm.so(tvm::relay::backend::GraphRuntimeCodegen::VisitExpr(tvm::relay::Expr const&)+0x47f) [0x7f5bb4d3464f]\n  [bt] (3) /home/ubuntu/tvm/build/libtvm.so(tvm::relay::backend::GraphRuntimeCodegen::VisitExpr_(tvm::relay::LetNode const*)+0x147) [0x7f5bb4d33c07]\n  [bt] (2) /home/ubuntu/tvm/build/libtvm.so(tvm::relay::backend::GraphRuntimeCodegen::VisitExpr(tvm::relay::Expr const&)+0x42d) [0x7f5bb4d345fd]\n  [bt] (1) /home/ubuntu/tvm/build/libtvm.so(tvm::relay::backend::GraphRuntimeCodegen::VisitExpr_(tvm::relay::CallNode const*)+0xd92) [0x7f5bb4d3a062]\n  [bt] (0) /home/ubuntu/tvm/build/libtvm.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x32) [0x7f5bb46c2352]\n  File \"/home/ubuntu/tvm/src/relay/backend/graph_runtime_codegen.cc\", line 397\nTVMError: TVM only support calls to primitive functions (i.e functions composed of fusable operator invocations)"
     ]
    }
   ],
   "source": [
    "opt_level = 1\n",
    "target = \"llvm\"\n",
    "with relay.build_config(opt_level=opt_level):\n",
    "    graph, lib, params = relay.build_module.build(\n",
    "        mod, target, params=params)\n",
    "\n",
    "ctx = tvm.cpu()\n",
    "data_dict = {}\n",
    "seq_len = 2\n",
    "for i in range(seq_len):\n",
    "    k = \"data_\" + str(i)\n",
    "    v = shape_dict[k]\n",
    "    data_dict[k] = np.random.uniform(\n",
    "        -1, 1, size=v.concrete_shape).astype(v.dtype)\n",
    "module = graph_runtime.create(graph, lib, ctx)\n",
    "for k, v in data_dict:\n",
    "    module.set_input(k, v)\n",
    "module.set_input(**params)\n",
    "module.run()\n",
    "outshape = (1, 2)\n",
    "out = module.get_output(0, tvm.nd.empty(out_shape)).asnumpy()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = relay.Module()\n",
    "p = Prelude(mod)\n",
    "l = p.l\n",
    "nil = p.nil\n",
    "cons = p.cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_lstm(seq_len, input_size, hidden_size, batch_size=1, dtype=\"float32\"):\n",
    "    input_type, hidden_type, i2h_weight_type, h2h_weight_type, bias_type, _, \\\n",
    "        _, state_type = get_types(input_size, hidden_size, batch_size, dtype)\n",
    "    \n",
    "    input_seq = nil()\n",
    "    for i in range(seq_len):\n",
    "        inputs = relay.Var(\"data\", input_type)\n",
    "        input_seq = cons(inputs, input_seq)\n",
    "    \n",
    "    i2h_weight = relay.Var(\"i2h_weight\", i2h_weight_type)\n",
    "    i2h_bias = relay.Var(\"i2h_bias\", bias_type)\n",
    "    h2h_weight = relay.Var(\"h2h_weight\", h2h_weight_type)\n",
    "    h2h_bias = relay.Var(\"h2h_bias\", bias_type)\n",
    "    \n",
    "    current_seq = relay.Var(\"current_seq\", l(input_type))\n",
    "    current_inputs = relay.Var(\"current_inputs\", input_type)\n",
    "    tail_seq = relay.Var(\"tail_seq\", l(input_type))\n",
    "    \n",
    "    rec_fn = relay.Var(\"rec_fn\")\n",
    "    cell_fn = lstm_cell(input_size, hidden_size, batch_size, dtype)\n",
    "    \n",
    "    builder = relay.ScopeBuilder()\n",
    "    zeros = builder.let((\"zeros\", hidden_type), relay.zeros((batch_size, hidden_size), dtype))\n",
    "    init_states = builder.let((\"init_states\", state_type), relay.Tuple([zeros, zeros]))\n",
    "    match = builder.let((\"match\", state_type), \n",
    "        relay.Match(\n",
    "            current_seq,\n",
    "            [relay.Clause(relay.PatternConstructor(nil), \n",
    "                          init_states),\n",
    "             relay.Clause(relay.PatternConstructor(cons,\n",
    "                                                   [relay.PatternVar(current_inputs), \n",
    "                                                    relay.PatternVar(tail_seq)]),\n",
    "                          relay.Call(cell_fn, [current_inputs, rec_fn(tail_seq),\n",
    "                                               i2h_weight, i2h_bias, h2h_weight, h2h_bias]))\n",
    "            ]))\n",
    "    builder.ret(match)\n",
    "    func = relay.Function([current_seq], builder.get())\n",
    "    ret = relay.Let(rec_fn, func, rec_fn(input_seq))\n",
    "    out = relay.TupleGetItem(ret, 0)\n",
    "    args = relay.analysis.free_vars(out)\n",
    "    return relay.Function(args, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nil' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e7fc13f92561>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"main\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecursive_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"main\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"main\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-b199b24a99a9>\u001b[0m in \u001b[0;36mrecursive_lstm\u001b[0;34m(seq_len, input_size, hidden_size, batch_size, dtype)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minput_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi2h_weight_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh2h_weight_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0minput_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nil' is not defined"
     ]
    }
   ],
   "source": [
    "mod[\"main\"] = recursive_lstm(2, 2, 2)\n",
    "mod = relay.transform.InferType()(mod)\n",
    "print(mod[\"main\"])\n",
    "print(mod[\"main\"].params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0.0.4\n",
      "fn (%data: Tensor[(1, 2), float32], %i2h_weight: Tensor[(8, 2), float32], %i2h_bias: Tensor[(8), float32], %h2h_weight: Tensor[(8, 2), float32], %h2h_bias: Tensor[(8), float32], %data1: Tensor[(1, 2), float32]) -> Tensor[(1, 2), float32] {\n",
      "  let %zeros: Tensor[(1, 2), float32] = zeros(shape=[1, 2], dtype=\"float32\") /* ty=Tensor[(1, 2), float32] */;\n",
      "  let %init_states: (Tensor[(1, 2), float32], Tensor[(1, 2), float32]) = (%zeros, %zeros);\n",
      "  %9 = fn (%inputs: Tensor[(1, 2), float32], %states: (Tensor[(1, 2), float32], Tensor[(1, 2), float32]), %i2h_weight1: Tensor[(8, 2), float32], %i2h_bias1: Tensor[(8), float32], %h2h_weight1: Tensor[(8, 2), float32], %h2h_bias1: Tensor[(8), float32]) -> (Tensor[(1, 2), float32], Tensor[(1, 2), float32]) {\n",
      "    let %old_h: Tensor[(1, 2), float32] = %states.0;\n",
      "    let %old_c: Tensor[(1, 2), float32] = %states.1;\n",
      "    %0 = nn.dense(%inputs, %i2h_weight1, units=8) /* ty=Tensor[(1, 8), float32] */;\n",
      "    let %i2h: Tensor[(1, 8), float32] = nn.bias_add(%0, %i2h_bias1, axis=-1) /* ty=Tensor[(1, 8), float32] */;\n",
      "    %1 = nn.dense(%old_h, %h2h_weight1, units=8) /* ty=Tensor[(1, 8), float32] */;\n",
      "    let %h2h: Tensor[(1, 8), float32] = nn.bias_add(%1, %h2h_bias1, axis=-1) /* ty=Tensor[(1, 8), float32] */;\n",
      "    let %gates: Tensor[(1, 8), float32] = add(%i2h, %h2h) /* ty=Tensor[(1, 8), float32] */;\n",
      "    let %slice_gates: (Tensor[(1, 2), float32], Tensor[(1, 2), float32], Tensor[(1, 2), float32], Tensor[(1, 2), float32]) = split(%gates, indices_or_sections=4, axis=1) /* ty=(Tensor[(1, 2), float32], Tensor[(1, 2), float32], Tensor[(1, 2), float32], Tensor[(1, 2), float32]) */;\n",
      "    %2 = %slice_gates.0;\n",
      "    let %in_gate: Tensor[(1, 2), float32] = sigmoid(%2) /* ty=Tensor[(1, 2), float32] */;\n",
      "    %3 = %slice_gates.1;\n",
      "    let %forget_gate: Tensor[(1, 2), float32] = sigmoid(%3) /* ty=Tensor[(1, 2), float32] */;\n",
      "    %4 = %slice_gates.2;\n",
      "    let %in_transform: Tensor[(1, 2), float32] = tanh(%4) /* ty=Tensor[(1, 2), float32] */;\n",
      "    %5 = %slice_gates.3;\n",
      "    let %out_gate: Tensor[(1, 2), float32] = sigmoid(%5) /* ty=Tensor[(1, 2), float32] */;\n",
      "    %6 = multiply(%forget_gate, %old_c) /* ty=Tensor[(1, 2), float32] */;\n",
      "    %7 = multiply(%in_gate, %in_transform) /* ty=Tensor[(1, 2), float32] */;\n",
      "    let %next_c: Tensor[(1, 2), float32] = add(%6, %7) /* ty=Tensor[(1, 2), float32] */;\n",
      "    %8 = tanh(%next_c) /* ty=Tensor[(1, 2), float32] */;\n",
      "    let %next_h: Tensor[(1, 2), float32] = multiply(%out_gate, %8) /* ty=Tensor[(1, 2), float32] */;\n",
      "    let %ret: (Tensor[(1, 2), float32], Tensor[(1, 2), float32]) = (%next_h, %next_c);\n",
      "    %ret\n",
      "  };\n",
      "  let %call: (Tensor[(1, 2), float32], Tensor[(1, 2), float32]) = %9(%data, %init_states, %i2h_weight, %i2h_bias, %h2h_weight, %h2h_bias) /* ty=(Tensor[(1, 2), float32], Tensor[(1, 2), float32]) */;\n",
      "  let %call1: (Tensor[(1, 2), float32], Tensor[(1, 2), float32]) = %9(%data1, %call, %i2h_weight, %i2h_bias, %h2h_weight, %h2h_bias) /* ty=(Tensor[(1, 2), float32], Tensor[(1, 2), float32]) */;\n",
      "  let %out: Tensor[(1, 2), float32] = %call1.0;\n",
      "  %out\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(mod[\"main\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_anaconda3)",
   "language": "python",
   "name": "conda_anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
