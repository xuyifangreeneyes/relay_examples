{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.relay.testing import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_types(input_size, hidden_size, batch_size=1, dtype=\"float32\"):\n",
    "    input_type = relay.TensorType((batch_size, input_size), dtype)\n",
    "    hidden_type = relay.TensorType((batch_size, hidden_size), dtype)\n",
    "    i2h_weight_type = relay.TensorType((4 * hidden_size, input_size), dtype)\n",
    "    h2h_weight_type = relay.TensorType((4 * hidden_size, hidden_size), dtype)\n",
    "    bias_type = relay.TensorType((4 * hidden_size,), dtype)\n",
    "    dense_type = relay.TensorType((batch_size, 4 * hidden_size), dtype)\n",
    "    slice_type = relay.TupleType([hidden_type, hidden_type, hidden_type, hidden_type])\n",
    "    state_type = relay.TupleType([hidden_type, hidden_type])\n",
    "    return input_type, hidden_type, i2h_weight_type, h2h_weight_type, bias_type, dense_type, slice_type, state_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_cell(input_size, hidden_size, batch_size=1, dtype=\"float32\"): \n",
    "    input_type, hidden_type, i2h_weight_type, h2h_weight_type, bias_type, dense_type, \\\n",
    "        slice_type, state_type = get_types(input_size, hidden_size, batch_size, dtype)\n",
    "    inputs = relay.Var(\"inputs\", input_type)\n",
    "    states = relay.Var(\"states\", state_type)\n",
    "    i2h_weight = relay.Var(\"i2h_weight\", i2h_weight_type)\n",
    "    i2h_bias = relay.Var(\"i2h_bias\", bias_type)\n",
    "    h2h_weight = relay.Var(\"h2h_weight\", h2h_weight_type)\n",
    "    h2h_bias = relay.Var(\"h2h_bias\", bias_type)\n",
    "    \n",
    "    builder = relay.ScopeBuilder()\n",
    "    old_h = builder.let((\"old_h\", hidden_type), relay.TupleGetItem(states, 0))\n",
    "    old_c = builder.let((\"old_c\", hidden_type), relay.TupleGetItem(states, 1))\n",
    "    i2h = builder.let((\"i2h\", dense_type),\n",
    "                      layers.dense_add_bias(\n",
    "                          data=inputs,\n",
    "                          units=hidden_size * 4,\n",
    "                          weight=i2h_weight, bias=i2h_bias,\n",
    "                          name=\"i2h\"))\n",
    "    h2h = builder.let((\"h2h\", dense_type),\n",
    "                      layers.dense_add_bias(\n",
    "                          data=old_h,\n",
    "                          units=hidden_size * 4,\n",
    "                          weight=h2h_weight, bias=h2h_bias,\n",
    "                          name=\"h2h\"))\n",
    "    gates = builder.let((\"gates\", dense_type), relay.add(i2h, h2h))\n",
    "    slice_gates = builder.let((\"slice_gates\", slice_type),\n",
    "                              relay.split(gates,\n",
    "                                          indices_or_sections=4,\n",
    "                                          axis=1).astuple())\n",
    "    in_gate = builder.let((\"in_gate\", hidden_type),\n",
    "                          relay.sigmoid(relay.TupleGetItem(slice_gates, 0)))\n",
    "    forget_gate = builder.let((\"forget_gate\", hidden_type),\n",
    "                              relay.sigmoid(relay.TupleGetItem(slice_gates, 1)))\n",
    "    in_transform = builder.let((\"in_transform\", hidden_type),\n",
    "                               relay.tanh(relay.TupleGetItem(slice_gates, 2)))\n",
    "    out_gate = builder.let((\"out_gate\", hidden_type),\n",
    "                           relay.sigmoid(relay.TupleGetItem(slice_gates, 3)))\n",
    "    next_c = builder.let((\"next_c\", hidden_type),\n",
    "                         relay.add(relay.multiply(forget_gate, old_c),\n",
    "                                   relay.multiply(in_gate, in_transform)))\n",
    "    next_h = builder.let((\"next_h\", input_type),\n",
    "                         relay.multiply(out_gate, relay.tanh(next_c)))\n",
    "    ret = builder.let((\"ret\", state_type), relay.Tuple([next_h, next_c]))\n",
    "    builder.ret(ret)\n",
    "\n",
    "    return relay.Function([inputs, states, i2h_weight, i2h_bias, h2h_weight, h2h_bias],\n",
    "                          builder.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unroll_lstm(seq_len, input_size, hidden_size, batch_size=1, dtype=\"float32\"):\n",
    "    input_type, hidden_type, i2h_weight_type, h2h_weight_type, bias_type, _, \\\n",
    "        _, state_type = get_types(input_size, hidden_size, batch_size, dtype)\n",
    "    \n",
    "    i2h_weight = relay.Var(\"i2h_weight\", i2h_weight_type)\n",
    "    i2h_bias = relay.Var(\"i2h_bias\", bias_type)\n",
    "    h2h_weight = relay.Var(\"h2h_weight\", h2h_weight_type)\n",
    "    h2h_bias = relay.Var(\"h2h_bias\", bias_type)\n",
    "    \n",
    "    cell_fn = lstm_cell(input_size, hidden_size, batch_size, dtype)\n",
    "    \n",
    "    builder = relay.ScopeBuilder()\n",
    "    zeros = builder.let((\"zeros\", hidden_type), relay.zeros((batch_size, hidden_size), dtype))\n",
    "    states = builder.let((\"init_states\", state_type), relay.Tuple([zeros, zeros]))\n",
    "    \n",
    "    for i in range(seq_len):\n",
    "        inputs = relay.Var(\"data_\" + str(i), input_type)\n",
    "        new_states = builder.let((\"call\", state_type),\n",
    "                                 relay.Call(cell_fn, [inputs, states, i2h_weight, \n",
    "                                                      i2h_bias, h2h_weight, h2h_bias]))\n",
    "        states = new_states\n",
    "    \n",
    "    out = builder.let((\"out\", hidden_type), relay.TupleGetItem(states, 0))\n",
    "    builder.ret(out)\n",
    "    body = builder.get()\n",
    "    args = relay.analysis.free_vars(body)\n",
    "    return relay.Function(args, body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Var(data_0, ty=TensorType([1, 2], float32)), Var(i2h_weight, ty=TensorType([8, 2], float32)), Var(i2h_bias, ty=TensorType([8], float32)), Var(h2h_weight, ty=TensorType([8, 2], float32)), Var(h2h_bias, ty=TensorType([8], float32)), Var(data_1, ty=TensorType([1, 2], float32))]\n",
      "[<tvm.NDArray shape=(1, 2), cpu(0)>\n",
      "array([[0.7290906 , 0.12898292]], dtype=float32), <tvm.NDArray shape=(8, 2), cpu(0)>\n",
      "array([[ 1.1394007 , -1.2348258 ],\n",
      "       [ 0.40234163, -0.6848101 ],\n",
      "       [-0.87079716, -0.5788497 ],\n",
      "       [-0.31155252,  0.05616534],\n",
      "       [-1.1651498 ,  0.9008265 ],\n",
      "       [ 0.46566245, -1.5362437 ],\n",
      "       [ 1.4882522 ,  1.8958892 ],\n",
      "       [ 1.1787796 , -0.17992483]], dtype=float32), <tvm.NDArray shape=(8,), cpu(0)>\n",
      "array([-1.0707526 ,  1.0544517 , -0.40317693,  1.222445  ,  0.20827498,\n",
      "        0.97663903,  0.3563664 ,  0.7065732 ], dtype=float32), <tvm.NDArray shape=(8, 2), cpu(0)>\n",
      "array([[ 0.01050002,  1.7858706 ],\n",
      "       [ 0.12691209,  0.40198937],\n",
      "       [ 1.8831507 , -1.347759  ],\n",
      "       [-1.270485  ,  0.9693967 ],\n",
      "       [-1.1731234 ,  1.9436212 ],\n",
      "       [-0.41361898, -0.7474548 ],\n",
      "       [ 1.922942  ,  1.4805148 ],\n",
      "       [ 1.867559  ,  0.90604466]], dtype=float32), <tvm.NDArray shape=(8,), cpu(0)>\n",
      "array([-0.86122566,  1.9100649 , -0.26800337,  0.8024564 ,  0.947252  ,\n",
      "       -0.15501009,  0.61407936,  0.9222067 ], dtype=float32), <tvm.NDArray shape=(1, 2), cpu(0)>\n",
      "array([[ 0.37642553, -1.0994008 ]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot find config for target=llvm, workload=('dense', (1, 2, 'float32'), (8, 2, 'float32'), 0, 'float32'). A fallback configuration is used, which may bring great performance regression.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tvm.relay.backend.vmobj.Tensor object at 0x7f15c1e9d388>\n"
     ]
    }
   ],
   "source": [
    "mod = relay.Module()\n",
    "mod[\"main\"] = unroll_lstm(2, 2, 2)\n",
    "mod = relay.transform.InferType()(mod)\n",
    "# print(mod[\"main\"])\n",
    "# print(mod[\"main\"].params)\n",
    "# print(mod[\"main\"].get_params)\n",
    "\n",
    "# shape_dict = {\n",
    "#     v.name_hint : v.checked_type for v in mod[\"main\"].params}\n",
    "# np.random.seed(0)\n",
    "# initializer = relay.testing.init.Xavier()\n",
    "# params = {}\n",
    "# for k, v in shape_dict.items():\n",
    "#     if k.startswith(\"data\"):\n",
    "#         continue\n",
    "#     init_value = np.zeros(v.concrete_shape).astype(v.dtype)\n",
    "#     initializer(k, init_value)\n",
    "#     params[k] = tvm.nd.array(init_value, ctx=tvm.cpu(0))\n",
    "\n",
    "inputs = []\n",
    "for v in mod[\"main\"].params:\n",
    "    t = v.checked_type\n",
    "    rand_value = np.random.normal(size=t.concrete_shape).astype(t.dtype)\n",
    "    inputs.append(tvm.nd.array(rand_value, ctx=tvm.cpu(0)))\n",
    "print(inputs)\n",
    "ctx = tvm.cpu()\n",
    "target = \"llvm\"\n",
    "vm = relay.create_executor('vm', ctx=tvm.cpu(), target=target, mod=mod)\n",
    "result = vm.evaluate()(*inputs)\n",
    "print(result.asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7610377   0.12167501  0.44386324]\n",
      " [ 0.33367434  1.4940791  -0.20515826]]\n"
     ]
    }
   ],
   "source": [
    "print(np.random.normal(size=(2, 3)).astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_anaconda3)",
   "language": "python",
   "name": "conda_anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
